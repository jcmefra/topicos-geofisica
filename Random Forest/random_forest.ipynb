{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción y generalidades\n",
    "\n",
    "El algoritmo de **Random Forest**, o **Bosque Aleatorio**, es un método de aprendizaje automático supervisado que se utiliza comúnmente para resolver problemas de clasificación y regresión. Fue registrado por Leo Breiman y Adele Cutler. Este algoritmo es popular debido a su facilidad de uso y flexibilidad.\n",
    "\n",
    "El algoritmo de Random Forest se basa en la combinación de la salida de múltiples árboles de decisión para alcanzar un solo resultado. Cada uno de estos árboles de decisión se genera a partir de diferentes muestras del conjunto de datos.\n",
    "\n",
    "Los **árboles de decisión** son algoritmos comunes de aprendizaje supervisado que comienzan con una pregunta básica y, a partir de ahí, hacen una serie de preguntas para determinar una respuesta. Estas preguntas constituyen los nodos de decisión en el árbol, actuando como un medio para dividir los datos.\n",
    "\n",
    "Aunque los árboles de decisión son útiles, pueden ser propensos a problemas como sesgos y sobreajuste. Sin embargo, cuando varios árboles de decisión forman un conjunto en el algoritmo de Random Forest, predicen resultados más precisos, especialmente cuando los árboles individuales no están correlacionados entre sí.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cómo funciona y en qué se basa\n",
    "\n",
    "El algoritmo de Random Forest funciona a través de una serie de pasos:\n",
    "\n",
    "1. **Selección de muestras**: El algoritmo selecciona aleatoriamente \"n\" números de registros del conjunto de datos.\n",
    "2. **Construcción de árboles de decisión**: Se construyen árboles de decisión individuales para cada muestra. Cada árbol de decisión se genera a partir de diferentes muestras del conjunto de datos.\n",
    "3. **Predicción**: Cada árbol de decisión generará una salida. La salida final depende de la mayoría o el promedio para la clasificación y la regresión, respectivamente.\n",
    "\n",
    "El algoritmo Random Forest se basa en la combinación de la salida de múltiples árboles de decisión para alcanzar un solo resultado. Este método se conoce como un método de conjunto (o ensemble method, en inglés), es decir, que combina resultados para obtener un superresultado final.\n",
    "\n",
    "Cada árbol en el bosque aleatorio se construye a partir de una muestra extraída con reemplazo (es decir, una muestra bootstrap) del conjunto de datos de entrenamiento. Además, al construir cada árbol, cada vez que se considera una división, un subconjunto aleatorio de las características se elige como candidatos divididos. Esto introduce más variabilidad entre los árboles en el modelo y, en última instancia, resulta en un modelo más robusto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Fundamentos matemáticos del algoritmo\n",
    "\n",
    "El algoritmo de Random Forest se basa en dos conceptos matemáticos fundamentales: **árboles de decisión** y **ensamblado**.\n",
    "\n",
    "#### Árboles de decisión\n",
    "\n",
    "Un árbol de decisión es una estructura de flujo que toma un conjunto de entradas y las divide en ramas, cada una representando una decisión basada en una característica. Cada división es un nodo, y el nodo final sin divisiones se llama nodo hoja, que proporciona la salida o la decisión.\n",
    "\n",
    "La creación de un árbol de decisión implica seleccionar las características que dividen el conjunto de datos de la mejor manera posible. Esto se hace utilizando medidas como la **ganancia de información**, que se basa en la **entropía** (una medida de la impureza en un subconjunto de datos).\n",
    "\n",
    "La ganancia de información se calcula como:\n",
    "\n",
    "$$\n",
    "\\text{Ganancia}(S, A) = \\text{Entropía}(S) - \\sum_{v \\in \\text{Valores}(A)}\\left(\\frac{|S_v|}{|S|}\\right) \\times \\text{Entropía}(S_v)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $S$ es el conjunto de datos.\n",
    "- $A$ es un atributo o característica.\n",
    "- $\\text{Valores}(A)$ son los valores posibles para la característica.\n",
    "- $S_v$ es el subconjunto de $S$ para el cual la característica $A$ tiene valor $v$.\n",
    "\n",
    "Las fórmulas principales utilizadas en la construcción de un árbol de decisión son las siguientes:\n",
    "\n",
    "1. **Entropía**: La entropía es una medida de la impureza o desorden en un conjunto de datos. Se utiliza para calcular la homogeneidad de las muestras en un nodo. La fórmula para calcular la entropía es:\n",
    "\n",
    "    $$\n",
    "    \\text{Entropía}(S) = - \\sum p_i \\log_2 p_i\n",
    "    $$\n",
    "\n",
    "    donde $p_i$ es la proporción de las instancias que pertenecen a la clase $i$.\n",
    "\n",
    "\n",
    "2. **Índice Gini**: El índice Gini es otra medida de impureza o desorden utilizada en el algoritmo CART (Classification and Regression Trees). Es una alternativa a la entropía y se calcula como:\n",
    "\n",
    "    $$\n",
    "    \\text{Gini}(S) = 1 - \\sum (p_i)^2\n",
    "    $$\n",
    "\n",
    "    donde $p_i$ es la proporción de las instancias que pertenecen a la clase $i$.\n",
    "\n",
    "Estas fórmulas se utilizan iterativamente para construir el árbol, seleccionando en cada paso el atributo que maximiza la ganancia de información (o minimiza el índice Gini en el caso del algoritmo CART) y dividiendo el conjunto de datos según los valores de ese atributo.\n",
    "\n",
    "#### Ensamblado\n",
    "\n",
    "El ensamblado es una técnica que combina las predicciones de múltiples modelos para obtener una predicción final más precisa y robusta. En el caso del Random Forest, el ensamblado se realiza utilizando el método de **bagging**.\n",
    "\n",
    "El bagging implica generar múltiples conjuntos de datos a partir del conjunto original mediante muestreo con reemplazo (cada conjunto tiene el mismo tamaño que el original, pero algunas instancias pueden aparecer varias veces y otras no aparecer) llamado boostraping. Luego, se entrena un árbol de decisión en cada conjunto.\n",
    "\n",
    "La predicción final del Random Forest se obtiene realizando una votación entre las predicciones de todos los árboles. En problemas de clasificación, la clase con más votos es la predicción final; en problemas de regresión, la media (o mediana) de las predicciones es la salida final.\n",
    "\n",
    "Estos fundamentos matemáticos permiten al algoritmo Random Forest manejar eficazmente tanto problemas lineales como no lineales, con alta dimensionalidad y con posibles interacciones entre características. Además, gracias a su naturaleza ensamblada, este algoritmo es menos propenso al sobreajuste que un único árbol de decisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Sintaxis del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos iris como ejemplo\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Crear un clasificador gaussiano\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Entrenar el modelo usando los conjuntos de entrenamiento y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predecir la respuesta para el conjunto de datos de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Precisión del modelo, ¿con qué frecuencia es correcto el clasificador?\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué hace cada parte del código:\n",
    "\n",
    "- **Importar las bibliotecas necesarias**: Este código importa las bibliotecas necesarias para crear un clasificador de bosques aleatorios, cargar un conjunto de datos, dividirlo en conjuntos de entrenamiento y prueba, y calcular la precisión del modelo.\n",
    "\n",
    "- **Cargar el conjunto de datos iris como ejemplo**: El conjunto de datos iris es un conjunto de datos simple y comúnmente utilizado en el aprendizaje automático. Contiene mediciones de 150 flores de iris de tres especies diferentes.\n",
    "\n",
    "- **Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba**: Este código divide el conjunto de datos en un conjunto de entrenamiento (70% de los datos) y un conjunto de prueba (30% de los datos). El parámetro `random_state` se utiliza para inicializar el generador interno de números aleatorios, que decidirá la división de los datos en índices de entrenamiento y prueba.\n",
    "\n",
    "- **Crear un clasificador gaussiano**: Esta línea crea un nuevo RandomForestClassifier. El parámetro `n_estimators` especifica el número de árboles en el bosque del modelo.\n",
    "\n",
    "- **Entrenar el modelo usando los conjuntos de entrenamiento**: La función `fit` se utiliza para entrenar el modelo con los datos de entrenamiento.\n",
    "\n",
    "- **Predecir la respuesta para el conjunto de datos de prueba**: La función `predict` se utiliza para predecir las respuestas para los datos de prueba.\n",
    "\n",
    "- **Precisión del modelo, ¿con qué frecuencia es correcto el clasificador?**: Finalmente, calculamos e imprimimos la precisión de nuestro modelo comparando nuestros valores predichos para el conjunto de prueba (`y_pred`) con sus valores reales (`y_test`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pros y contras, cuándo usarlo y cuándo no\n",
    "\n",
    "#### Pros\n",
    "\n",
    "1. **Manejo de datos de alta dimensión**: Random Forest puede manejar eficazmente conjuntos de datos con un gran número de características y observaciones.\n",
    "2. **Robustez a los valores atípicos**: Debido a la naturaleza del ensamblado y el muestreo, Random Forest es bastante robusto a los valores atípicos en los datos.\n",
    "3. **Menos preprocesamiento de datos**: No es necesario normalizar o escalar las características para Random Forest, lo que reduce la necesidad de preprocesamiento de datos.\n",
    "4. **Manejo de características no lineales e interacciones**: Random Forest puede capturar interacciones no lineales entre características, lo que puede ser difícil para otros algoritmos.\n",
    "5. **Estimaciones de importancia de características**: Random Forest proporciona una estimación directa de qué características son las más importantes en la predicción.\n",
    "\n",
    "#### Contras\n",
    "\n",
    "1. **Tiempo de entrenamiento**: Random Forest puede ser lento para entrenar si el número de árboles es grande.\n",
    "2. **Complejidad del modelo**: Un Random Forest puede ser un modelo complejo de entender e interpretar, en comparación con un árbol de decisión simple.\n",
    "3. **Predicciones fuera del rango**: En problemas de regresión, Random Forest no puede predecir más allá del rango de las observaciones en el conjunto de entrenamiento.\n",
    "\n",
    "#### Cuándo usarlo\n",
    "\n",
    "Random Forest es una buena opción cuando tienes un conjunto de datos con características categóricas o numéricas, y estás buscando un algoritmo que pueda manejar interacciones no lineales y que sea robusto a los valores atípicos.\n",
    "\n",
    "#### Cuándo no usarlo\n",
    "\n",
    "Es posible que no quieras usar Random Forest si necesitas un modelo muy rápido y eficiente en términos de tiempo de entrenamiento y predicción, o si necesitas hacer predicciones fuera del rango de tu conjunto de entrenamiento en problemas de regresión. También puede que no sea la mejor opción si necesitas un modelo muy interpretable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
