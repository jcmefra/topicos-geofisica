{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción y generalidades\n",
    "\n",
    "El algoritmo de **Random Forest**, o **Bosque Aleatorio**, es un método de aprendizaje automático supervisado que se utiliza comúnmente para resolver problemas de clasificación y regresión. Fue registrado por Leo Breiman y Adele Cutler. Este algoritmo es popular debido a su facilidad de uso y flexibilidad.\n",
    "\n",
    "El algoritmo de Random Forest se basa en la combinación de la salida de múltiples árboles de decisión para alcanzar un solo resultado. Cada uno de estos árboles de decisión se genera a partir de diferentes muestras del conjunto de datos.\n",
    "\n",
    "Los **árboles de decisión** son algoritmos comunes de aprendizaje supervisado que comienzan con una pregunta básica y, a partir de ahí, hacen una serie de preguntas para determinar una respuesta. Estas preguntas constituyen los nodos de decisión en el árbol, actuando como un medio para dividir los datos.\n",
    "\n",
    "Aunque los árboles de decisión son útiles, pueden ser propensos a problemas como sesgos y sobreajuste. Sin embargo, cuando varios árboles de decisión forman un conjunto en el algoritmo de Random Forest, predicen resultados más precisos, especialmente cuando los árboles individuales no están correlacionados entre sí.\n",
    "\n",
    "# 2. Cómo funciona y en qué se basa\n",
    "\n",
    "El algoritmo de Random Forest funciona a través de una serie de pasos:\n",
    "\n",
    "1. **Selección de muestras**: El algoritmo selecciona aleatoriamente \"n\" números de registros del conjunto de datos.\n",
    "2. **Construcción de árboles de decisión**: Se construyen árboles de decisión individuales para cada muestra. Cada árbol de decisión se genera a partir de diferentes muestras del conjunto de datos.\n",
    "3. **Predicción**: Cada árbol de decisión generará una salida. La salida final depende de la mayoría o el promedio para la clasificación y la regresión, respectivamente.\n",
    "\n",
    "El algoritmo Random Forest se basa en la combinación de la salida de múltiples árboles de decisión para alcanzar un solo resultado. Este método se conoce como un método de conjunto (o ensemble method, en inglés), es decir, que combina resultados para obtener un superresultado final.\n",
    "\n",
    "Cada árbol en el bosque aleatorio se construye a partir de una muestra extraída con reemplazo (es decir, una muestra bootstrap) del conjunto de datos de entrenamiento. Además, al construir cada árbol, cada vez que se considera una división, un subconjunto aleatorio de las características se elige como candidatos divididos. Esto introduce más variabilidad entre los árboles en el modelo y, en última instancia, resulta en un modelo más robusto.\n",
    "\n",
    "# 3. Fundamentos matemáticos del algoritmo\n",
    "\n",
    "El algoritmo de Random Forest se basa en dos conceptos matemáticos fundamentales: **árboles de decisión** y **ensamblado**.\n",
    "\n",
    "#### Árboles de decisión\n",
    "\n",
    "Un árbol de decisión es una estructura de flujo que toma un conjunto de entradas y las divide en ramas, cada una representando una decisión basada en una característica. Cada división es un nodo, y el nodo final sin divisiones se llama nodo hoja, que proporciona la salida o la decisión.\n",
    "\n",
    "La creación de un árbol de decisión implica seleccionar las características que dividen el conjunto de datos de la mejor manera posible. Esto se hace utilizando medidas como la **ganancia de información**, que se basa en la **entropía** (una medida de la impureza en un subconjunto de datos).\n",
    "\n",
    "La ganancia de información se calcula como:\n",
    "\n",
    "$$\n",
    "\\text{Ganancia}(S, A) = \\text{Entropía}(S) - \\sum_{v \\in \\text{Valores}(A)}\\left(\\frac{|S_v|}{|S|}\\right) \\times \\text{Entropía}(S_v)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $S$ es el conjunto de datos.\n",
    "- $A$ es un atributo o característica.\n",
    "- $\\text{Valores}(A)$ son los valores posibles para la característica.\n",
    "- $S_v$ es el subconjunto de $S$ para el cual la característica $A$ tiene valor $v$.\n",
    "\n",
    "#### Ensamblado\n",
    "\n",
    "El ensamblado es una técnica que combina las predicciones de múltiples modelos para obtener una predicción final más precisa y robusta. En el caso del Random Forest, el ensamblado se realiza utilizando el método de **bagging**.\n",
    "\n",
    "El bagging implica generar múltiples conjuntos de datos a partir del conjunto original mediante muestreo con reemplazo (cada conjunto tiene el mismo tamaño que el original, pero algunas instancias pueden aparecer varias veces y otras no aparecer). Luego, se entrena un árbol de decisión en cada conjunto.\n",
    "\n",
    "La predicción final del Random Forest se obtiene realizando una votación entre las predicciones de todos los árboles. En problemas de clasificación, la clase con más votos es la predicción final; en problemas de regresión, la media (o mediana) de las predicciones es la salida final.\n",
    "\n",
    "Estos fundamentos matemáticos permiten al algoritmo Random Forest manejar eficazmente tanto problemas lineales como no lineales, con alta dimensionalidad y con posibles interacciones entre características. Además, gracias a su naturaleza ensamblada, este algoritmo es menos propenso al sobreajuste que un único árbol de decisión.\n",
    "\n",
    "# 4. Sintaxis del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Supongamos que X e y son nuestros datos\n",
    "# X, y = tus_datos()\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializamos el clasificador Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluamos la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código primero divide los datos en conjuntos de entrenamiento y prueba. Luego inicializa un clasificador Random Forest con 100 árboles (n_estimators=100) y una profundidad máxima de 2 (max_depth=2). Después de entrenar el modelo en los datos de entrenamiento, hace predicciones en los datos de prueba y calcula la precisión del modelo.\n",
    "\n",
    "Es importante recordar que los hiperparámetros como n_estimators y max_depth deben ajustarse para tu problema específico. También puedes considerar otros hiperparámetros como max_features, que controla el número de características a considerar en cada división.\n",
    "\n",
    "Espero que este ejemplo te ayude a entender mejor cómo usar el algoritmo Random Forest en Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
